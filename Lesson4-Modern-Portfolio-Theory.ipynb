{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4: Machine Learning with Modern Portfolio Theory (MPT)\n",
    "\n",
    "## Intro\n",
    "\n",
    "In this notebook, you'll learn how to use modern portfolio theory (MPT) and the Sharpe ratio to plot and find optimal stock portfolios. You'll also use machine learning to predict the best portfolios. Finally, you'll evaluate the performance of the ML-predicted portfolios.\n",
    "\n",
    "First, let's load some code that we'll need to get started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install scikit-learn\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "lng_df = pd.read_csv('data/lng_mpt.csv')\n",
    "spy_df = pd.read_csv('data/spy_mpt.csv')\n",
    "smlv_df = pd.read_csv('data/smlv_mpt.csv')\n",
    "\n",
    "lng_df.set_index('Date', inplace=True)\n",
    "lng_df.index = pd.to_datetime(lng_df.index)\n",
    "spy_df.set_index('Date', inplace=True)\n",
    "spy_df.index = pd.to_datetime(spy_df.index)\n",
    "smlv_df.set_index('Date', inplace=True)\n",
    "smlv_df.index = pd.to_datetime(smlv_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Stock DataFrames and Calculate Returns \n",
    "Our first step towards calculating modern portfolio theory (MPT) portfolios is to get daily and monthly returns. Eventually we're going to get the best portfolios of each month based on the Sharpe ratio. The easiest way to do this is to put all our stock prices into one DataFrame, then to resample them to the daily and monthly time frames. We need daily price changes to calculate volatility, which we will use as our measure of risk.\n",
    "\n",
    "### Instructions\n",
    "* Join together `lng_df`, `spy_df`, and `smlv_df` using `pd.concat()` into the `full_df` DataFrame\n",
    "* Resample the `full_df` to Business Month Start (`'BMS'`) frequency.\n",
    "* Get the daily percent change of `full_df` with `.pct_change()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join 3 stock dataframes together\n",
    "full_df = pd.concat(____, axis=1).dropna()\n",
    "\n",
    "# Resample the full dataframe to monthly timeframe\n",
    "monthly_df = full_df.resample(____).first()\n",
    "\n",
    "# Calculate daily returns of stocks\n",
    "returns_daily = ____\n",
    "\n",
    "# Calculate monthly returns of the stocks\n",
    "returns_monthly = monthly_df.pct_change().dropna()\n",
    "print(returns_monthly.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Covariances for Volatility\n",
    "\n",
    "In MPT, we quantify risk via volatility. The math for calculating portfolio volatility is complex, and it requires daily returns covariances. We'll now loop through each month in the `returns_monthly` DataFrame, and calculate the covariance of the daily returns.\n",
    "\n",
    "With pandas datetime indices, we can access the month and year with `df.index.month` and `df.index.year`. We'll use this to create a mask for `returns_daily` that gives us the daily returns for the current month and year in the loop. We then use the mask to subset the DataFrame like this: `df[mask]`. This gets entries in the `returns_daily` DataFrame which are in the current month and year in each cycle of the loop. Finally, we'll use pandas' `.cov()` method to get the covariance of daily returns.\n",
    "\n",
    "### Instructions\n",
    "* Loop through the index of `returns_monthly`.\n",
    "* Create a mask for `returns_daily` which uses the current month and year from `returns_monthly`, and matches this to the current month and year from `i` in the loop.\n",
    "* Use the mask on `returns_daily` and calculate covariances using `.cov()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily covariance of stocks (for each monthly period)\n",
    "covariances = {}\n",
    "rtd_idx = returns_daily.index\n",
    "for i in returns_monthly.____:    \n",
    "    # Mask daily returns for each month and year, and calculate covariance\n",
    "    mask = (rtd_idx.month == i.month) & (rtd_idx.____ == i.____)\n",
    "    \n",
    "    # Use the mask to get daily returns for the current month and year of monthy returns index\n",
    "    covariances[i] = returns_daily[____].cov()\n",
    "\n",
    "print(covariances[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Portfolios\n",
    "We'll now generate portfolios to find each month's best one. `numpy`'s `random.random()` generates random numbers from a uniform distribution, then we normalize them so they sum to 1 using the /= operator. We use these weights to calculate returns and volatility. Returns are sums of weights times individual returns. Volatility is more complex, and involves the covariances of the different stocks.\n",
    "\n",
    "Finally we'll store the values in dictionaries for later use, with months' dates as keys.\n",
    "\n",
    "In this case, we will only generate 10 portfolios for each date so the code will run faster, but in a real-world use-case you'd want to use more like 1000 to 5000 randomly-generated portfolios for a few stocks.-m pip install matplotlib\n",
    "\n",
    "### Instructions\n",
    "* Generate **3** random numbers for the weights using `np.random.random()`.\n",
    "* Calculate returns by taking the dot product (`np.dot()`; multiplies element-by-element and sums up two arrays) of `weights` with the monthly returns for the current `date` in the loop.\n",
    "* Use the `.setdefault()` method to add an empty list (`[]`) to the `portfolio_weights` dictionary for the current `date`, then append `weights` to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_returns, portfolio_volatility, portfolio_weights = {}, {}, {}\n",
    "\n",
    "# Get portfolio performances at each month\n",
    "for date in sorted(covariances.keys()):\n",
    "    cov = covariances[date]\n",
    "    for portfolio in range(10):\n",
    "        weights = np.random.random(____)\n",
    "        weights /= np.sum(weights) # /= divides weights by their sum to normalize\n",
    "        returns = np.dot(____, returns_monthly.loc[____])\n",
    "        volatility = np.sqrt(np.dot(weights.T, np.dot(cov, weights)))\n",
    "        portfolio_returns.setdefault(date, []).append(returns)\n",
    "        portfolio_volatility.setdefault(date, []).append(volatility)\n",
    "        portfolio_weights.setdefault(date, ____).append(____)\n",
    "        \n",
    "print(portfolio_weights[date][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Efficient Frontier\n",
    "We can finally plot the results of our MPT portfolios, which shows the \"efficient frontier\". This is a plot of the volatility vs the returns. This can help us visualize our risk-return possibilities for portfolios. The upper left boundary of the points is the best we can do (highest return for a given risk), and that is the efficient frontier.\n",
    "\n",
    "To create this plot, we will use the latest date in our `covariances` dictionary which we created a few exercises ago. This has dates as keys, so we'll get the sorted keys using `sorted()` and `.keys()`, then get the last entry with Python indexing (`[-1]`). Lastly we'll use `matplotlib` to scatter variance vs returns and see the efficient frontier for the latest date in the data.\n",
    "\n",
    "### Instructions\n",
    "* Get the latest date from the `covariances` dictionary - remember the dates are the keys.\n",
    "* Plot the volatility vs returns (`portfolio_returns`) for the latest date in a scatter plot, and set the `alpha` value for transparency to be `0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get latest date of available data\n",
    "date = sorted(covariances.____)[____]  \n",
    "\n",
    "# Plot efficient frontier\n",
    "# warning: this can take at least 10s for the plot to execute...\n",
    "plt.scatter(x=portfolio_volatility[date], y=____,  alpha=____)\n",
    "plt.xlabel('Volatility')\n",
    "plt.ylabel('Returns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Best Sharpe Ratios\n",
    "We need to find the \"ideal\" portfolios for each date so we can use them as targets for machine learning. We'll loop through each date in `portfolio_returns`, then loop through the portfolios we generated with `portfolio_returns[date]`. We'll then calculate the Sharpe ratio, which is the return divided by volatility (assuming a no-risk return of 0).\n",
    "\n",
    "We use `enumerate()` to loop through the returns for the current date (`portfolio_returns[date]`) and keep track of the index with `i`. Then we use the current date and current index to get the volatility of each portfolio with `portfolio_volatility[date][i]`. Finally, we get the index of the best Sharpe ratio for each date using `np.argmax()`. We'll use this index to get the ideal portfolio weights soon.\n",
    "\n",
    "### Instructions\n",
    "* Using `enumerate()`, enumerate the `portfolio_returns` for each date in the loop.\n",
    "* For the current `date` in the loop, append to the `sharpe_ratio` dictionary entry with the return (`ret`) divided by `portfolio_volatility` for the current date and current `i` in the loops.\n",
    "* Set the value for the current date's `max_sharpe_idxs` to be the index of the maximum Sharpe ratio using `np.argmax()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty dictionaries for sharpe ratios and best sharpe indexes by date\n",
    "sharpe_ratio, max_sharpe_idxs = {}, {}\n",
    "\n",
    "# Loop through dates and get sharpe ratio for each portfolio\n",
    "for date in portfolio_returns.keys():\n",
    "    for i, ret in enumerate(portfolio_returns[____]):\n",
    "    \n",
    "        # Divide returns by the volatility for the date and index, i\n",
    "        sharpe_ratio.setdefault(date, []).append(____ / portfolio_volatility[date][____])\n",
    "\n",
    "    # Get the index of the best sharpe ratio for each date\n",
    "    max_sharpe_idxs[date] = np.argmax(sharpe_ratio[____])\n",
    "\n",
    "print(portfolio_returns[date][max_sharpe_idxs[date]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate EWMAs\n",
    "We will now work towards creating some features to be able to predict our ideal portfolios. We will simply use the price movement as a feature for now. To do this we will create a daily exponentially-weighted moving average (EWMA), then resample that to the monthly timeframe. Finally, we'll shift the monthly moving average of price one month in the future, so we can use it as a feature for predicting future portfolios.\n",
    "\n",
    "### Instructions\n",
    "* Use a `span` of 30 to calculate the daily exponentially-weighted moving average (`ewa_daily`).\n",
    "* Resample the daily ewma to the month by using the Business Monthly Start frequency (BMS) and the first day of hte month (`.first()`).\n",
    "* Shift `ewma_monthly` by one month forward, so we can use the previous month's EWMA as a feature to predict the next month's ideal portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate exponentially-weighted moving average of daily returns\n",
    "ewma_daily = returns_daily.ewm(span=____).mean()\n",
    "\n",
    "# Resample daily returns to first business day of the month with the first day for that month\n",
    "ewma_monthly = ewma_daily.resample(____).____\n",
    "\n",
    "# Shift ewma for the month by 1 month forward so we can use it as a feature for future predictions \n",
    "ewma_monthly = ewma_monthly.____.dropna()\n",
    "\n",
    "print(ewma_monthly.iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Features and Targets\n",
    "To use machine learning to pick the best portfolio, we need to generate features and targets. Our features were just created in the last exercise – the exponentially weighted moving averages of prices. Our targets will be the best portfolios we found from the highest Sharpe ratio.\n",
    "\n",
    "We will use pandas' `.iterrows()` method to get the `index, value` pairs for the `ewma_monthly` DataFrame. We'll set the current value of ewma_monthly in the loop to be our features. Then we'll use the index of the best Sharpe ratio (from `max_sharpe_idxs`) to get the best `portfolio_weights` for each month and set that as a target.\n",
    "\n",
    "### Instructions\n",
    "* Use the `.iterrows()` method with `ewma_monthly` to iterate through the `index_value` in the loop.\n",
    "* Use the `date` in the loop and `best_idx` to index `portfolio_weights` to get the ideal portfolio weights based on the best Sharpe ratio.\n",
    "* Append the `ewma` to the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets, features = [], []\n",
    "\n",
    "# Create features from price history and targets as ideal portfolio\n",
    "for date, ewma in ewma_monthly.____:\n",
    "\n",
    "    # Get the index of the best sharpe ratio\n",
    "    best_idx = max_sharpe_idxs[date]\n",
    "    targets.append(portfolio_weights[____][____])\n",
    "    features.append(____)  # add ewma to features\n",
    "\n",
    "targets = np.array(targets)\n",
    "features = np.array(features)\n",
    "print(targets[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Efficient Fronteir with Best Sharpe Ratio\n",
    "Let's now plot the efficient frontier again, but add a marker for the portfolio with the best Sharpe index. Visualizing our data is always a good idea to better understand it.\n",
    "\n",
    "Recall the efficient frontier is plotted in a scatter plot of portfolio volatility on the x-axis, and portfolio returns on the y-axis. We'll get the latest date we have in our data from `covariances.keys()`, although any of the `portfolio_returns`, etc, dictionaries could be used as well to get the date. Then we get volatilities and returns for the latest date we have from our `portfolio_volatility` and `portfolio_returns`. Finally we get the index of the portfolio with the best Sharpe index from `max_sharpe_idxs[date]`, and plot everything with `plt.scatter()`.\n",
    "\n",
    "### Instructions\n",
    "* Set `cur_volatility` to be the portfolio volatilities for the latest `date`.\n",
    "* Construct the \"efficient frontier\" plot by plotting volatility on the x-axis and returns on the y-axis.\n",
    "* Get the best portfolio index for the latest `date` from `max_sharpe_idxs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most recent (current) returns and volatility\n",
    "date = sorted(covariances.keys())[-1]\n",
    "cur_returns = portfolio_returns[date]\n",
    "cur_volatility = ____\n",
    "\n",
    "# Plot efficient frontier with sharpe as point\n",
    "plt.scatter(x=____, y=____, alpha=0.1, color='blue')\n",
    "best_idx = max_sharpe_idxs[____]\n",
    "\n",
    "# Place an orange \"X\" on the point with the best Sharpe ratio\n",
    "plt.scatter(x=cur_volatility[best_idx], y=cur_returns[best_idx], marker='x', color='orange')\n",
    "plt.xlabel('Volatility')\n",
    "plt.ylabel('Returns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictoins with a Random Forest\n",
    "In order to fit a machine learning model to predict ideal portfolios, we need to create train and test sets for evaluating performance. We will do this as we did in previous chapters, where we take our `features` and `targets` arrays, and split them based on a `train_size` we set. Often the train size may be around 70-90% of our data.\n",
    "\n",
    "We then fit our model (a random forest in this case) to the training data, and evaluate the R^2 scores on train and test using `.score()` from our model. In this case, the hyperparameters have been set for you, but usually you'd want to do a search with `ParameterGrid` like we did in previous notebooks.\n",
    "\n",
    "### Instructions\n",
    "* Set the `train_size` to be 85% of the full training set data using the `.shape` property of `features`.\n",
    "* Create train and test targets from `targets` using Python indexing.\n",
    "* Fit the random forest model to the `train_features` and `train_targets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make train and test features\n",
    "train_size = int(0.85 * ____)\n",
    "train_features = features[:train_size]\n",
    "test_features = features[train_size:]\n",
    "train_targets = targets[____]\n",
    "test_targets = targets[____]\n",
    "\n",
    "# Fit the model and check scores on train and test\n",
    "rfr = RandomForestRegressor(n_estimators=300, random_state=42)\n",
    "rfr.fit(____, ____)\n",
    "print(rfr.score(train_features, train_targets))\n",
    "print(rfr.score(test_features, test_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Predictions and First Evaluation\n",
    "Now that we have a trained random forest model (`rfr`), we want to use it to get predictions on the test set. We do this to evaluate our model's performance – at a basic level, is it doing as well or better than just buying the index, SPY?\n",
    "\n",
    "We'll use the typical sklearn `.predict(features)` method, then multiply our monthly returns by our portfolio predictions. We sum these up with `np.sum()` since this will have 3 rows for each month. Then we plot both the monthly returns from our predictions, as well as SPY and compare the two.\n",
    "\n",
    "### Instructions\n",
    "* Use the `rfr` random forest model's `.predict()` method to make predictions on `train_features` and `test_features`.\n",
    "* Multiply the test set portion of `returns_monthly` by `test_predictions` to get the returns of our test set predictions.\n",
    "* Plot the test set `returns_monthly` for `'SPY'` (everything from `train_size` to the end of the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from model on train and test\n",
    "train_predictions = rfr.predict(train_features)\n",
    "test_predictions = ____\n",
    "\n",
    "# Calculate and plot returns from our RF predictions and the SPY returns\n",
    "test_returns = np.sum(returns_monthly.iloc[train_size:] * ____, axis=1)\n",
    "plt.plot(test_returns, label='algo')\n",
    "plt.plot(returns_monthly['SPY'].iloc[____], label='SPY')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Returns\n",
    "Let's now see how our portfolio selection would perform as compared with just investing in the SPY. We'll do this to see if our predictions are promising, despite the low R2 value.\n",
    "\n",
    "We will set a starting value for our investment of $ 1000, then loop through the returns from our predictions as well as from SPY. We'll use the monthly returns from our portfolio selection and SPY and apply them to our starting cash balance. From this we will get a month-by-month picture of how our investment is doing, and we can see how our predictions did overall vs the SPY. Next, we can plot our portfolio from our predictions and compare it to SPY.\n",
    "\n",
    "### Instructions\n",
    "* Set the first list entries of both `algo_cash` and `spy_cash` to the same amount (`cash`).\n",
    "* Multiply the cash in our `test_returns` loop by `1 + r` in order to apply the returns to our `cash`.\n",
    "* As with the `test_returns` loop, in the SPY performance loop, append `cash` to spy_cash after multiplying by `1 + r` to add the returns to `cash`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the effect of our portfolio selection on a hypothetical $1k investment\n",
    "cash = 1000\n",
    "algo_cash, spy_cash = [cash], ____  # set equal starting cash amounts\n",
    "for r in test_returns:\n",
    "    cash *= 1 + r\n",
    "    algo_cash.append(cash)\n",
    "\n",
    "# Calculate performance for SPY\n",
    "cash = 1000  # reset cash amount\n",
    "for r in returns_monthly['SPY'].iloc[train_size:]:\n",
    "    cash ____ ____\n",
    "    ____\n",
    "\n",
    "print('algo returns:', (algo_cash[-1] - algo_cash[0]) / algo_cash[0])\n",
    "print('SPY returns:', (spy_cash[-1] - spy_cash[0]) / spy_cash[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Returns\n",
    "Lastly, we'll plot the performance of our machine-learning-generated portfolio versus just holding the SPY. We can use this as an evaluation to see if our predictions are doing well or not.\n",
    "\n",
    "Since we already have `algo_cash` and `spy_cash` created, all we need to do is provide them to `plt.plot()` to display. We'll also set the label for the datasets with legend in `plt.plot()`.\n",
    "\n",
    "### Instructions\n",
    "* Use `plt.plot()` to plot the `algo_cash` (with label `'algo'`) and `spy_cash` (with label `'SPY'`).\n",
    "* Use `plt.legend()` to display the legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the algo_cash and spy_cash to compare overall returns\n",
    "plt.plot(____, ____)\n",
    "plt.plot(spy_cash, label='SPY')\n",
    "____  # show the legend\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

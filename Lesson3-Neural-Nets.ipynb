{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3: Neural Networks and KNN\n",
    "\n",
    "## Recap Lesson 2\n",
    "\n",
    "Today, we will learn how to normalize and scale data for use in KNN and neural network methods. Then we will learn how to use KNN and neural network regression to predict the future values of a stock's price.\n",
    "\n",
    "First, let's load our code from previous lessons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install TA-Lib\n",
    "!{sys.executable} -m pip install seaborn\n",
    "!{sys.executable} -m pip install statsmodels\n",
    "!{sys.executable} -m pip install scikit-learn\n",
    "!{sys.executable} -m pip install tensorflow\n",
    "!{sys.executable} -m pip install keras==2.3.1\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import talib\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.losses\n",
    "from keras.layers import Dropout\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "lng_df = pd.read_csv('data/lng.csv')\n",
    "spy_df = pd.read_csv('data/spy.csv')\n",
    "\n",
    "# Change index for Lesson 2\n",
    "lng_df.set_index('Date', inplace=True)\n",
    "lng_df.index = pd.to_datetime(lng_df.index)\n",
    "\n",
    "spy_df.set_index('Date', inplace=True)\n",
    "spy_df.index = pd.to_datetime(spy_df.index)\n",
    "\n",
    "\n",
    "# Create 5-day % changes of Adj_Close for the current day, and 5 days in the future\n",
    "lng_df['5d_future_close'] = lng_df['Adj_Close'].shift(-5)\n",
    "lng_df['5d_close_future_pct'] = lng_df['5d_future_close'].pct_change(5)\n",
    "lng_df['5d_close_pct'] = lng_df['Adj_Close'].pct_change(5)\n",
    "\n",
    "feature_names = ['5d_close_pct']  # a list of the feature names for later\n",
    "\n",
    "# Create moving averages and rsi for timeperiods of 14, 30, 50, and 200\n",
    "for n in [14, 30, 50, 200]:\n",
    "\n",
    "    # Create the moving average indicator and divide by Adj_Close\n",
    "    lng_df['ma' + str(n)] = talib.SMA(lng_df['Adj_Close'].values,\n",
    "                              timeperiod=n) / lng_df['Adj_Close']\n",
    "    # Create the RSI indicator\n",
    "    lng_df['rsi' + str(n)] = talib.RSI(lng_df['Adj_Close'].values, timeperiod=n)\n",
    "    \n",
    "    # Add rsi and moving average to the feature name list\n",
    "    feature_names = feature_names + ['ma' + str(n), 'rsi' + str(n)]\n",
    "\n",
    "\n",
    "# Create features and targets\n",
    "# use feature_names for features; '5d_close_future_pct' for targets\n",
    "features = lng_df.dropna()[feature_names]\n",
    "targets = lng_df.dropna()['5d_close_future_pct']\n",
    "\n",
    "# Create DataFrame from target column and feature columns\n",
    "feature_and_target_cols = ['5d_close_future_pct'] + feature_names\n",
    "feat_targ_df = lng_df[feature_and_target_cols]\n",
    "\n",
    "# Add a constant to the features\n",
    "linear_features = sm.add_constant(features)\n",
    "\n",
    "# Create a size for the training set that is 85% of the total number of samples\n",
    "train_size = int(0.85 * features.shape[0])\n",
    "train_features = linear_features[:train_size]\n",
    "train_targets = targets[:train_size]\n",
    "test_features = linear_features[train_size:]\n",
    "test_targets = targets[train_size:]\n",
    "\n",
    "# Create 2 new volume features, 1-day % change and 5-day SMA of the % change\n",
    "new_features = ['Adj_Volume_1d_change', 'Adj_Volume_1d_change_SMA']\n",
    "feature_names.extend(new_features)\n",
    "lng_df['Adj_Volume_1d_change'] = lng_df['Adj_Volume'].pct_change()\n",
    "lng_df['Adj_Volume_1d_change_SMA'] = talib.SMA(lng_df['Adj_Volume_1d_change'].values,\n",
    "                        timeperiod=5)\n",
    "\n",
    "# Use pandas' get_dummies function to get dummies for day of the week\n",
    "days_of_week = pd.get_dummies(lng_df.index.dayofweek,\n",
    "                              prefix='weekday',\n",
    "                              drop_first=True)\n",
    "# Set the index as the original dataframe index for merging\n",
    "days_of_week.index = lng_df.index\n",
    "\n",
    "# Join the dataframe with the days of week dataframe\n",
    "\n",
    "lng_df = pd.concat([lng_df, days_of_week], axis=1)\n",
    "# Add days of week to feature names\n",
    "feature_names.extend(['weekday_' + str(i) for i in range(1, 5)])\n",
    "lng_df.dropna(inplace=True)  # drop missing values in-place\n",
    "\n",
    "# Add the weekday labels to the new_features list\n",
    "new_features.extend(['weekday_' + str(i) for i in range(1, 5)])\n",
    "\n",
    "# Create a decision tree regression model with default arguments\n",
    "decision_tree = DecisionTreeRegressor()\n",
    "\n",
    "train_features = lng_df[feature_names].iloc[:250]\n",
    "test_features = lng_df[feature_names].iloc[250:]\n",
    "\n",
    "# Fit the model to the training features and targets\n",
    "decision_tree.fit(train_features, train_targets)\n",
    "\n",
    "# Loop through a few different max depths and check the performance\n",
    "for d in [3, 5, 10]:\n",
    "    # Create the tree and fit it\n",
    "    decision_tree = DecisionTreeRegressor(max_depth = d)\n",
    "    decision_tree.fit(train_features, train_targets)\n",
    "\n",
    "# Use the best max_depth of 3 from last exercise to fit a decision tree\n",
    "decision_tree = DecisionTreeRegressor(max_depth=3)\n",
    "decision_tree.fit(train_features, train_targets)\n",
    "\n",
    "# Predict values for train and test\n",
    "train_predictions = decision_tree.predict(train_features)\n",
    "test_predictions = decision_tree.predict(test_features)\n",
    "\n",
    "# Create the random forest model and fit to the training data\n",
    "rfr = RandomForestRegressor(n_estimators=200)\n",
    "rfr.fit(train_features, train_targets)\n",
    "\n",
    "# Create a dictionary of hyperparameters to search\n",
    "grid = {'n_estimators': [200], 'max_depth': [3], 'max_features': [4,8], 'random_state': [42]}\n",
    "test_scores = []\n",
    "\n",
    "# Loop through the parameter grid, set the hyperparameters, and save the scores\n",
    "for g in ParameterGrid(grid):\n",
    "    rfr.set_params(**g)  # ** is \"unpacking\" the dictionary\n",
    "    rfr.fit(train_features, train_targets)\n",
    "    test_scores.append(rfr.score(test_features, test_targets))\n",
    "\n",
    "# Find best hyperparameters from the test score and print\n",
    "best_idx = np.argmax(test_scores)\n",
    "\n",
    "# Use the best hyperparameters from before to fit a random forest model\n",
    "rfr = RandomForestRegressor(n_estimators=200, max_depth=3, max_features=4, random_state=42)\n",
    "rfr.fit(train_features, train_targets)\n",
    "\n",
    "# Make predictions with our model\n",
    "train_predictions = rfr.predict(train_features)\n",
    "test_predictions = rfr.predict(test_features)\n",
    "\n",
    "# Get feature importances from our random forest model\n",
    "importances = rfr.feature_importances_\n",
    "\n",
    "# Get the index of importances from greatest importance to least\n",
    "sorted_index = np.argsort(importances)[::-1]\n",
    "x = range(len(importances))\n",
    "\n",
    "# Create tick labels \n",
    "labels = np.array(feature_names)[sorted_index]\n",
    "\n",
    "# Create GB model -- hyperparameters have already been searched for you\n",
    "gbr = GradientBoostingRegressor(max_features=4,\n",
    "                                learning_rate=0.01,\n",
    "                                n_estimators=200,\n",
    "                                subsample=0.6,\n",
    "                                random_state=42)\n",
    "gbr.fit(train_features, train_targets)\n",
    "\n",
    "# Extract feature importances from the fitted gradient boosting model\n",
    "feature_importances = gbr.feature_importances_\n",
    "\n",
    "# Get the indices of the largest to smallest feature importances\n",
    "sorted_index = np.argsort(feature_importances)[::-1]\n",
    "features = lng_df.dropna()[feature_names]\n",
    "x = range(features.shape[1])\n",
    "\n",
    "# Create tick labels \n",
    "labels = np.array(feature_names)[sorted_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing Data\n",
    "Some models, like K-nearest neighbors (KNN) & neural networks, work better with scaled data - so we'll standardize our data.\n",
    "\n",
    "We'll also remove unimportant variables (day of week), according to feature importances, by indexing the features DataFrames with `.iloc[]`. KNN uses distances to find similar points for predictions, so big features outweigh small ones. Scaling data fixes that.\n",
    "\n",
    "`sklearn`'s `scale()` will standardize data, which sets the mean to 0 and standard deviation to 1.\n",
    "\n",
    "Once we've scaled the data, we'll check that it worked by plotting histograms of the data.\n",
    "\n",
    "### Instructions\n",
    "* Remove day of the week features from train/test features using `.iloc` (day of the week are the last 4 features).\n",
    "* Standardize `train_features` and `test_features` using `sklearn`'s `scale()`; store scaled features as `scaled_train_features` and `scaled_test_features`.\n",
    "* Plot a histogram of the 14-day RSI moving average (indexed at `[:, 2]`) from unscaled `trained_features` on the first subplot (`ax[0]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unimportant features (weekdays)\n",
    "train_features = train_features.iloc[:, :-4]\n",
    "test_features = test_features.____\n",
    "\n",
    "# Standardize the train and test features\n",
    "scaled_train_features = scale(train_features)\n",
    "scaled_test_features = ____\n",
    "\n",
    "# Plot histograms of the 14-day SMA RSI before and after scaling\n",
    "f, ax = plt.subplots(nrows=2, ncols=1)\n",
    "train_features.iloc[:, 2].hist(ax=____)\n",
    "ax[1].hist(scaled_train_features[:, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice work! Next we're going to optimize n_neighbors for improved performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize n_neighbors\n",
    "\n",
    "Now that we have scaled data, we can try using a KNN model. To maximize performance, we should tune our model's hyperparameters. For the k-nearest neighbors algorithm, we only have one hyperparameter: `n`, the number of neighbors. We set this hyperparameter when we create the model with `KNeighborsRegressor`. The argument for the number of neighbors is `n_neighbors`.\n",
    "\n",
    "We want to try a range of values that passes through the setting with the best performance. Usually we will start with 2 neighbors, and increase until our scoring metric starts to decrease. We'll use the R^2 value from the `.score()` method on the test set (`scaled_test_features` and `test_targets`) to optimize n here. We'll use the test set scores to determine the best `n`.\n",
    "\n",
    "### Instructions\n",
    "* Loop through the values of 2 to 12 for `n` and set this as `n_neighbors` in the `knn` model.\n",
    "* Fit the model to the training data (`scaled_train_features` and `train_targets`). \n",
    "* Print out the R^2 values using the `.score()` method of the `knn` model for the train and test sets, and take note of the best score on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(____):\n",
    "    # Create and fit the KNN model\n",
    "    knn = KNeighborsRegressor(n_neighbors=____)\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    knn.fit(____, ____)\n",
    "    \n",
    "    # Print number of neighbors and the score to find the best value of n\n",
    "    print(\"n_neighbors =\", n)\n",
    "    print('train, test scores')\n",
    "    print(knn.score(scaled_train_features, train_targets))\n",
    "    print(knn.score(____, ____))\n",
    "    print()  # prints a blank line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice work! See how 5 is the best number of neighbors based on the test score?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate KNN performance\n",
    "\n",
    "We just saw a few things with our KNN scores. For one, the training scores started high and decreased with increasing `n`, which is typical. The test set performance reached a peak at 5 though, and we will use that as our setting in the final KNN model.\n",
    "\n",
    "As we have done a few times now, we will check our performance visually. This helps us see how well the model is predicting on different regions of actual values. We will get predictions from our `knn` model using the `.predict()` method on our scaled features. Then we'll use `matplotlib`'s `plt.scatter()` to create a scatter plot of actual versus predicted values.\n",
    "\n",
    "### Instructions\n",
    "* Set `n_neighborrs` in the `KNeighborsRegressor` to the best performing value of 5.\n",
    "* Obtain predictions using the `knn` model from the `scaled_train_features` and `scaled_test_features`.\n",
    "* Create a scatter plot of the `test_targets` versus the `test_predictions` and label it `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with the best-performing n_neighbors of 5\n",
    "knn = KNeighborsRegressor(____)\n",
    "\n",
    "# Fit the model\n",
    "knn.fit(scaled_train_features, train_targets)\n",
    "\n",
    "# Get predictions for train and test sets\n",
    "train_predictions = ____\n",
    "test_predictions = ____\n",
    "\n",
    "# Plot the actual vs predicted values\n",
    "plt.scatter(train_predictions, train_targets, label='train')\n",
    "plt.scatter(____)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! It looks like this model is showing some hope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and fit a simple neural net\n",
    "The next model we will learn how to use is a neural network. Neural nets can capture complex interactions between variables, but are difficult to set up and understand. Recently, they have been beating human experts in many fields, including image recognition and gaming (check out AlphaStar from Deepmind) - so they have great potential to perform well.\n",
    "\n",
    "To build our nets we'll use the `keras` library. This is a high-level API that allows us to quickly make neural nets, yet still exercise a lot of control over the design. The first thing we'll do is create almost the simplest net possible - a 3-layer net that takes our inputs and predicts a single value. Much like the `sklearn` models, keras models have a `.fit()` method that takes arguments of (`features`, `targets`).\n",
    "\n",
    "### Instructions\n",
    "* Create a dense layer with 20 nodes and the ReLU (`'relu'`) activation as the 2nd layer in the neural network.\n",
    "* Create the last dense layer with 1 node and a linear activation (`activation='linear'`).\n",
    "* Fit the model to the `scaled_train_features` and `train_targets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(100, input_dim=scaled_train_features.shape[1], activation='relu'))\n",
    "model_1.add(Dense(____, activation=____))\n",
    "model_1.add(Dense(____, activation=____))\n",
    "\n",
    "# Fit the model\n",
    "model_1.compile(optimizer='adam', loss='mse')\n",
    "history = model_1.fit(____, ____, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! Now we need to check that our training loss has flattened out and the net is sufficiently trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot losses\n",
    "\n",
    "Once we've fit a model, we usually check the training loss curve to make sure it's flattened out. The `history` returned from `model.fit()` is a dictionary that has an entry, `'loss'`, which is the training loss. We want to ensure this has more or less flattened out at the end of our training.\n",
    "\n",
    "### Instructions\n",
    "* Plot the losses (`'loss'`) from `history.history`.\n",
    "* Set the title of the plot as the last loss from `history.history`, and round it to 6 digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the losses from the fit\n",
    "plt.plot(____)\n",
    "\n",
    "# Use the last loss as the title\n",
    "plt.title('loss:' + str(round(____, 6)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice work! We can see our loss has flattened out, so we're good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure Performance\n",
    "Now that we've fit our neural net, let's check performance to see how well our model is predicting new values. There's not a built-in `.score()` method like with `sklearn` models, so we'll use the `r2_score()` function from `sklearn.metrics`. This calculates the R^2 score given arguments (`y_true`, `y_predicted`). We'll also plot our predictions versus actual values again. This will yield some interesting results soon (once we implement our own custom loss function).\n",
    "\n",
    "### Instructions\n",
    "* Obtain predictions from `model_1` on the scaled test set data (`scaled_test_features` and `test_targets`).\n",
    "* Print the R^2 score on the test set (`test_targets` and `test_preds`).\n",
    "* Plot the `test_preds` versus `test_targets` in a scatter plot with `plt.scatter()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate R^2 score\n",
    "train_preds = model_1.predict(scaled_train_features)\n",
    "test_preds = model_1.predict(____)\n",
    "print(r2_score(train_targets, train_preds))\n",
    "print(r2_score(____, ____))\n",
    "\n",
    "# Plot predictions vs actual\n",
    "plt.scatter(train_preds, train_targets, label='train')\n",
    "plt.scatter(____)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice work! It doesn't look too much different from our other models just yet, don't lose hope!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom loss function\n",
    "Up to now, we've used the mean squared error as a loss function. This works fine, but with stock price prediction it can be useful to implement a custom loss function. A custom loss function can help improve our model's performance in specific ways we choose. For example, we're going to create a custom loss function with a large penalty for predicting price movements in the wrong direction. This will help our net learn to at least predict price movements in the correct direction.\n",
    "\n",
    "To do this, we need to write a function that takes arguments of (`y_true`, `y_predicted`). We'll also use functionality from the backend `keras` (using `tensorflow`) to find cases where the true value and prediction don't match signs, then penalize those cases.\n",
    "\n",
    "### Instructions\n",
    "* Set the arguments of the `sign_penalty(`) function to be `y_true` and `y_pred`.\n",
    "* Multiply the squared error (`tf.square(y_true - y_pred)`) by penalty when the signs of `y_true` and `y_pred` are different.\n",
    "* Return the average of the loss variable from the function - this is the mean squared error (with our penalty for opposite signs of actual vs predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss function\n",
    "def sign_penalty(____, ____):\n",
    "    penalty = 100.\n",
    "    loss = tf.where(tf.less(y_true * y_pred, 0), \\\n",
    "                     ____ * tf.square(y_true - y_pred), \\\n",
    "                     tf.square(y_true - y_pred))\n",
    "\n",
    "    return tf.reduce_mean(____, axis=-1)\n",
    "\n",
    "keras.losses.sign_penalty = sign_penalty  # enable use of loss with keras\n",
    "print(keras.losses.sign_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! Now we'll see how that loss function affects our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit neural net with custom loss function\n",
    "Now we'll use the custom loss function we just created. This will enable us to alter the model's behavior in useful ways particular to our problem - it's going to try to force the model to learn how to at least predict price movement direction correctly. All we need to do now is set the `loss` argument in our `.compile()` function to our function name, `sign_penalty`. We'll examine the training loss again to make sure it's flattened out.\n",
    "\n",
    "### Instructions\n",
    "* Set the `input_dim` of the first neural network layer to be the number of columns of `scaled_train_features` with the `.shape[1]` property.\n",
    "* Use the custom `sign_penalty` loss function to `.compile()` our `model_2`.\n",
    "* Plot the loss from the `history` of the fit. The loss is under `history.history['loss']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(100, input_dim=____, activation='relu'))\n",
    "model_2.add(Dense(20, activation='relu'))\n",
    "model_2.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Fit the model with our custom 'sign_penalty' loss function\n",
    "model_2.compile(optimizer='adam', loss=____)\n",
    "history = model_2.fit(scaled_train_features, train_targets, epochs=25)\n",
    "plt.plot(____)\n",
    "plt.title('loss:' + str(round(history.history['loss'][-1], 6)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results\n",
    "We've fit our model with the custom loss function, and it's time to see how it is performing. We'll check the R^2 values again with `sklearn`'s `r2_score()` function, and we'll create a scatter plot of predictions versus actual values with `plt.scatter()`. This will hopefully yield some interesting results!\n",
    "\n",
    "### Instructions\n",
    "* Create predictions on the test set with `.predict()`, `model_2`, and `scaled_test_features`.\n",
    "* Evaluate the R^2 score on the test set predictions using `test_preds` and `test_targets`.\n",
    "* Plot the test set targets vs actual values with `plt.scatter()`, and label it `'test'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate R^2 scores\n",
    "train_preds = model_2.predict(scaled_train_features)\n",
    "test_preds = ____\n",
    "print(r2_score(train_targets, train_preds))\n",
    "print(____)\n",
    "\n",
    "# Scatter the predictions vs actual -- this one is interesting!\n",
    "plt.scatter(train_preds, train_targets, label='train')\n",
    "plt.scatter(____)  # plot test set\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice work! Notice how the train set actual vs predictions shape has changed to be a bow-tie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combatting overfitting with dropout\n",
    "A common problem with neural networks is they tend to overfit to training data. What this means is the scoring metric, like R^2 or accuracy, is high for the training set, but low for testing and validation sets, and the model is fitting to noise in the training data.\n",
    "\n",
    "We can work towards preventing overfitting by using dropout. This randomly drops some neurons during the training phase, which helps prevent the net from fitting noise in the training data. `keras` has a `Dropout` layer that we can use to accomplish this. We need to set the dropout rate, or fraction of connections dropped during training time. This is set as a decimal between 0 and 1 in the `Dropout()` layer.\n",
    "\n",
    "We're going to go back to the mean squared error loss function for this model.\n",
    "\n",
    "### Instructions\n",
    "* Add a dropout layer (`Dropout()`) after the first Dense layer in the model, and use 20% (0.2) as the dropout rate.\n",
    "* Use the `adam` optimizer and the mse loss function when compiling the model in `.compile()`.\n",
    "* Fit the model to the s`caled_train_features` and `train_targets` using 25 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with dropout\n",
    "model_3 = Sequential()\n",
    "model_3.add(Dense(100, input_dim=scaled_train_features.shape[1], activation='relu'))\n",
    "model_3.add(____)\n",
    "model_3.add(Dense(20, activation='relu'))\n",
    "model_3.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Fit model with mean squared error loss function\n",
    "model_3.compile(optimizer=____, loss=____)\n",
    "history = model_3.fit(____, ____, epochs=____)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('loss:' + str(round(history.history['loss'][-1], 6)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! Dropout helps the model generalized a bit better to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling models\n",
    "One approach to improve predictions from machine learning models is ensembling. A basic approach is to average the predictions from multiple models. A more complex approach is to feed predictions of models into *another* model, which makes final predictions. Both approaches usually improve our overall performance (as long as our individual models are good). If you remember, random forests are also using ensembling of many decision trees.\n",
    "\n",
    "To ensemble our neural net predictions, we'll make predictions with the 3 models we just created -- the basic model, the model with the custom loss function, and the model with dropout. Then we'll combine the predictions with `numpy`'s `.hstack()` function, and average them across rows with `np.mean(predictions, axis=1)`.\n",
    "\n",
    "### Instructions\n",
    "* Create predictions on the `scaled_train_features` and `scaled_test_features` for the 3 models we fit (`model_1`, `model_2`, `model_3`) using the `.predict()` method.\n",
    "* Horizontally stack (`np.hstack()` the predictions into a matrix, and take the row-wise averages to get average predictions for the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions from the 3 neural net models\n",
    "train_pred1 = model_1.predict(____)\n",
    "test_pred1 = model_1.predict(____)\n",
    "\n",
    "train_pred2 = ____\n",
    "test_pred2 = ____\n",
    "\n",
    "train_pred3 = model_3.predict(scaled_train_features)\n",
    "test_pred3 = model_3.predict(scaled_test_features)\n",
    "\n",
    "# Horizontally stack predictions and take the average across rows\n",
    "train_preds = np.mean(np.hstack((train_pred1, train_pred2, train_pred3)), axis=1)\n",
    "test_preds = np.mean(____, ____)\n",
    "print(test_preds[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good work! Now let's see how our ensemble predictions perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See how the ensemble performed\n",
    "Let's check performance of our ensembled model to see how it's doing. We should see roughly an average of the R^2 scores, as well as a scatter plot that is a mix of our previous models' predictions. The bow-tie shape from the custom loss function model should still be a bit visible, but the edges near x=0 should be softer.\n",
    "\n",
    "### Instructions\n",
    "* Evaluate the R2 scores on the train and test sets. Use the `sklearn` `r2_score()` function (already imported for you) with `train_targets` and `train_preds` from earlier.\n",
    "* Plot the train and test predictions versus the actual values with `plt.scatter()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the R^2 scores\n",
    "print(r2_score(____, ____))\n",
    "print(r2_score(test_targets, test_preds))\n",
    "\n",
    "# Scatter the predictions vs actual -- this one is interesting!\n",
    "plt.scatter(____, ____, ____)\n",
    "plt.scatter(test_preds, test_targets, label='test')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice work! Our R^2 values are around the average of the 3 models we ensembled. Notice the plot also looks like the bow-tie shape has been softened a bit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
